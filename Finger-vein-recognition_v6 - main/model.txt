-------------------------------------------------------------------------
      Layer (type)          Output Shape         Param #     Tr. Param #
=========================================================================
      PatchEmbed-1     [1, 32, 112, 112]             193             193
      PatchEmbed-2       [1, 32, 56, 56]           1,440           1,440
      BasicBlock-3       [1, 32, 56, 56]         232,006         232,006
      PatchEmbed-4       [1, 64, 28, 28]           2,528           2,528
      BasicBlock-5       [1, 64, 28, 28]         921,734         921,734
      PatchEmbed-6       [1, 96, 14, 14]           7,040           7,040
      BasicBlock-7       [1, 96, 14, 14]       2,069,190       2,069,190
      BasicBlock-8       [1, 96, 14, 14]       2,069,190       2,069,190
      BasicBlock-9       [1, 96, 14, 14]       2,069,190       2,069,190
     PatchEmbed-10        [1, 128, 7, 7]          13,600          13,600
     BasicBlock-11        [1, 128, 7, 7]       3,674,374       3,674,374
   LinearModule-12              [1, 360]          46,696          46,696
=========================================================================
Total params: 11,107,181
Trainable params: 11,107,181
Non-trainable params: 0
-------------------------------------------------------------------------
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.padding.ZeroPad2d'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.
[INFO] Register count_softmax() for <class 'torch.nn.modules.activation.Softmax'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.
[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm1d'>.
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
FLOPs: 2.8699 GFLOPs
Params: 11.1056 M
Computational complexity:       2.86 GMac